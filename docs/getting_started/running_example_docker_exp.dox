/*! \page running_example_docker_exp Running the example experiments in multiple docker containers

\image html multi_containers_deployment.png "Supported combinations of host/container execution for NRP-core and a containerized engine"

The folder `"examples"` contains four examples (listed in the table below) of how to use \ref DockerLauncher.
In each of these experiments there is a `simulation_config_docker.json` configuration file which uses \ref DockerLauncher to launch and run one of the engines in the experiment in a docker container.

<table>
<tr><th>Example folder<th>Description<th>DockerImage
<tr><td>husky_braitenberg<td>Running a gazebo_grpc engine with a husky model inside a docker container<td>nrp-core/nrp-gazebo-ubuntu20:latest
<tr><td>nest_simple<td>Running a nest_json engine with a simple nest model inside a docker container<td>nrp-core/nrp-nest-ubuntu20:latest
<tr><td>pysim_examples/opensim_control<td>Running a pysim engine with a arm26 model of OpenSim inside a docker container<td>nrp-core/nrp-opensim-ubuntu20:latest
<tr><td>tf_exchange<td>Running a python_json engine  inside a docker container<td>nrp-core/nrp-vanilla-ubuntu20:latest
</table>

The images referenced in the table can be manually built from the different dockerfiles available in the folder "/dockerfiles" using docker-compose.
For more information on how to use the provided dockerfiles to build custom, modular docker images with the necessary dependencies to run different Engines, see this \ref docker_compose "page".

As the figure shows, these experiments can be run in different configurations: NRP-core and the engines can be distributed (and containerized) in one or more hosts.
The manager host(s) of containerized engine stores the engine docker image and runs the Manager Server that responds to NRP-core requests.

To run the experiments, the users should first, on every host that requires the Manager Server (see Figure above), launch the latter using the python script in `"docker_manager/server"`.

\code{.sh}
python3 docker_launcher.py
\endcode

Since the husky model require vision devices, it needs to ask for devices library from the manager host. And its execution command is 

\code{.sh}
xhost +$USER
python3 docker_launcher.py
\endcode

Then, on the NRP host, one should run the experiment as usual. For example, for the example experiment that we provide:

\code{.sh}
cd examples/<example folder>
NRPCoreSim -c simulation_config_docker.json
\endcode

If the user wishes to run NRP-core inside a docker container, the docker container should be launched first:

\code{.sh}
docker run -it --network="host" --name <container name> <image name>
\endcode

The <b>`"host"`</b> network mode is required to simplify the configuration of the connectivity of the containerized components.

<b><em>NOTE:</em></b>

The IP addresses of the local and remote hosts have to be specified in the experiment configuration file:
- `"DockerServerAddress"` is the IP address of the remote Manager server.
- `"ServerAddress"` is IP address of remote engine
- `"RegistrationServerAddress"` is IP address of NRP-core

On the Manager host, the manager (i.e. docker_launcher.py) REST server will temporarily store (i.e. for the duration of the experiment) the experiment files and mount this folder on the container in which the engine is run.

*/
